{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchaudio import transforms\n",
    "\n",
    "from models.audio_LSTMCNN import AudioLSTMCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 44100\n",
    "MEL_SPECTROGRAM_BUCKETS = 128\n",
    "MEL_SPECTROGRAM_WINDOW_LENGTH = 224\n",
    "SPECTROS_PER_SECOND = RATE // (MEL_SPECTROGRAM_WINDOW_LENGTH / 2) - 1\n",
    "CHUNKS_PER_SECOND = 2\n",
    "CHUNK_SIZE_IN_SPECTROS = int(SPECTROS_PER_SECOND // CHUNKS_PER_SECOND)\n",
    "\n",
    "TRAINSET_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadrant(val: float, aro: float) -> int:\n",
    "    if val >= 0.5 and aro >= 0.5:\n",
    "        return 1\n",
    "    if val >= 0.5 and aro < 0.5:\n",
    "        return 2\n",
    "    if val < 0.5 and aro < 0.5:\n",
    "        return 3\n",
    "    if val < 0.5 and aro >= 0.5:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FOLDER = \"C:\\\\Users\\\\amity\\\\PycharmProjects\\\\aimpathy\\\\data\\\\PMEmo\\\\PMEmo2019\\\\chorus\"\n",
    "THAYER_ANOTATIONS_CSV = \"C:\\\\Users\\\\amity\\\\PycharmProjects\\\\aimpathy\\\\data\\\\PMEmo\\\\PMEmo2019\\\\annotations\\\\dynamic_annotations.csv\"\n",
    "thayer_annotations_df = pd.read_csv(THAYER_ANOTATIONS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amity\\Anaconda3\\envs\\aimpathy\\lib\\site-packages\\torchaudio\\functional\\functional.py:539: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (128) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_files = [f for f in os.listdir(AUDIO_FOLDER) if isfile(join(AUDIO_FOLDER, f))]\n",
    "audio_data = dict()\n",
    "torch_spectorgrams = dict()\n",
    "spectorgrammer = transforms.MelSpectrogram(sample_rate=RATE, n_fft=(MEL_SPECTROGRAM_BUCKETS * 2 - 2), win_length=MEL_SPECTROGRAM_WINDOW_LENGTH, power=2, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 794/794 [03:07<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "spectrograms = dict()\n",
    "for audio_file in tqdm(audio_files, total=len(audio_files)):\n",
    "    sound = AudioSegment.from_mp3(os.sep.join([AUDIO_FOLDER, audio_file])).set_channels(1)\n",
    "    audio_file_wave = sound.export(format=\"wav\", bitrate=RATE)\n",
    "    sample_rate, samples = wavfile.read(audio_file_wave)\n",
    "    spectogram = spectorgrammer(torch.from_numpy(samples/(2**15)).float().reshape((1, -1)))\n",
    "    spectrograms[audio_file] = spectogram\n",
    "    audio_file_wave.close()\n",
    "spectrograms = {key: value for key, value in spectrograms.items() if \".wav\" not in key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 793/793 [00:31<00:00, 25.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dict()  # music_id: spectrogram, (valence, arousal)\n",
    "for file_name, spectrogram in tqdm(spectrograms.items(), total=len(spectrograms)):\n",
    "    music_id = int(file_name.replace(\".mp3\", \"\"))\n",
    "    dataset[music_id] = list()\n",
    "    max_frame_time = thayer_annotations_df[thayer_annotations_df[\"musicId\"] == music_id][\"frameTime\"].max()\n",
    "    if np.isnan(max_frame_time):    \n",
    "        dataset.pop(music_id)\n",
    "        continue\n",
    "    for i in range(int(CHUNKS_PER_SECOND * max_frame_time)):\n",
    "        data_df = thayer_annotations_df[(thayer_annotations_df[\"musicId\"] == music_id) & (thayer_annotations_df[\"frameTime\"] == i/2)]\n",
    "        if data_df.empty:\n",
    "            #  print(f\"Skipping {musicI_id} - {i/2}\")\n",
    "            continue\n",
    "        valence = data_df.iloc[0][\"Valence(mean)\"]\n",
    "        arousal = data_df.iloc[0][\"Arousal(mean)\"]\n",
    "        dataset[music_id].append((spectrogram[0, :, int((i/2-1)*CHUNK_SIZE_IN_SPECTROS): int((i/2)*CHUNK_SIZE_IN_SPECTROS)], (valence, arousal)))\n",
    "    \n",
    "    if len(dataset[music_id]) <= 0:\n",
    "        dataset.pop(music_id)\n",
    "        \n",
    "music_id_to_quadrant = {key: get_quadrant(np.mean([val[1][0] for val in value]), np.mean([val[1][1] for val in value])) for key, value in dataset.items() if value}\n",
    "quadrant_counters = [list(music_id_to_quadrant.values()).count(i+1) for i in range(4)]\n",
    "quadrant_ratios = max(quadrant_counters)//np.array(quadrant_counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_music_ids = random.sample(dataset.keys(), int(TRAINSET_RATIO*len(dataset)))\n",
    "trainset = {key: value for key, value in dataset.items() if key in train_music_ids}\n",
    "testset = {key: value for key, value in dataset.items() if key not in train_music_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/datasets/trainset_{int(time.time())}.pk', 'wb') as f:\n",
    "    pickle.dump(list(trainset.keys()), f)\n",
    "with open(f'data/datasets/testset_{int(time.time())}.pk', 'wb') as f:\n",
    "    pickle.dump(list(testset.keys()), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label = '1674741184'\n",
    "with open(f'data/datasets/trainset_{dataset_label}.pk', 'rb') as f:\n",
    "    trainset_ids = pickle.load(f)\n",
    "    trainset = {key: value for key, value in dataset.items() if key in trainset_ids}\n",
    "with open(f'data/datasets/testset_{dataset_label}.pk', 'rb') as f:\n",
    "    testset_ids = pickle.load(f)\n",
    "    testset = {key: value for key, value in dataset.items() if key in testset_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_quadrant_to_keys = dict()\n",
    "\n",
    "for music_id in trainset.keys():\n",
    "    quad = music_id_to_quadrant[music_id]\n",
    "    if quad not in trainset_quadrant_to_keys:\n",
    "        trainset_quadrant_to_keys[quad] = list()\n",
    "    trainset_quadrant_to_keys[quad].append(music_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None, ymax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    if ymax:\n",
    "        axs.set_ylim((0, ymax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(dataset[1000][0], title=\"MelSpectrogram - torchaudio\", ylabel=\"mel freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'saved_models/AudioLSTMCNN_1674751233_014772344088200705.pt'\n",
    "model_c = AudioLSTMCNN()\n",
    "model_c.load_state_dict(torch.load(model_name));\n",
    "model_c.eval().cuda()\n",
    "print(\"Loaded model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = AudioLSTMCNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(model_c.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 196])\n",
      "torch.Size([1, 1, 128, 196])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[10][0][0].shape)\n",
    "print(dataset[10][0][0].reshape((1, 1, MEL_SPECTROGRAM_BUCKETS, -1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0-   0 | loss: 0.14007  |  [   0(   0),    0(   0),    1(   1),    0(   0)]     lr: 0.005\n",
      " 0- 500 | loss: 0.01984  |  [ 192( 193),   98( 108),  129(  89),   82( 111)]     lr: 0.005\n",
      " 0-1000 | loss: 0.01313  |  [ 294( 279),  217( 227),  282( 217),  208( 278)]     lr: 0.005\n",
      " 0-1500 | loss: 0.01372  |  [ 435( 400),  358( 403),  466( 377),  242( 321)]     lr: 0.005\n",
      " 1- 500 | loss: 0.07989  |  [ 207( 208),   45( 132),  162(   3),   87( 158)]     lr: 0.005\n",
      " 1-1000 | loss: 0.06225  |  [ 324( 285),  206( 349),  356( 152),  115( 215)]     lr: 0.005\n",
      " 1-1500 | loss: 0.04664  |  [ 436( 327),  256( 399),  611( 379),  198( 396)]     lr: 0.005\n",
      " 1-2000 | loss: 0.03803  |  [ 566( 449),  358( 536),  825( 559),  252( 457)]     lr: 0.005\n",
      " 2- 500 | loss: 0.01844  |  [ 160( 131),   80(  98),  175( 141),   86( 131)]     lr: 0.005\n",
      " 2-1000 | loss: 0.01660  |  [ 285( 261),  129( 181),  384( 299),  203( 260)]     lr: 0.005\n",
      " 2-1500 | loss: 0.01354  |  [ 473( 437),  318( 379),  437( 348),  273( 337)]     lr: 0.005\n",
      " 2-2000 | loss: 0.01260  |  [ 549( 502),  508( 576),  555( 434),  389( 489)]     lr: 0.005\n",
      " 3- 500 | loss: 0.00837  |  [ 103(  62),   63(  79),  127( 127),  208( 233)]     lr: 0.005\n",
      " 3-1000 | loss: 0.00708  |  [ 250( 193),  208( 266),  300( 262),  243( 280)]     lr: 0.005\n",
      " 3-1500 | loss: 0.00817  |  [ 489( 420),  287( 339),  409( 363),  316( 379)]     lr: 0.005\n",
      " 3-2000 | loss: 0.00754  |  [ 554( 490),  404( 446),  650( 606),  393( 459)]     lr: 0.005\n",
      " 4- 500 | loss: 0.00666  |  [  75(  66),  209( 234),  120( 104),   97(  97)]     lr: 0.005\n",
      " 4-1000 | loss: 1.94323  |  [ 319( 332),  301( 406),  248( 166),  133(  97)]     lr: 0.005\n",
      " 4-1500 | loss: 1.33470  |  [ 525( 502),  354( 483),  383( 209),  239( 307)]     lr: 0.005\n",
      " 4-2000 | loss: 1.01361  |  [ 636( 611),  484( 639),  566( 358),  315( 393)]     lr: 0.005\n",
      " 4-2500 | loss: 0.81388  |  [ 770( 681),  520( 650),  717( 472),  494( 698)]     lr: 0.005\n",
      " 5- 500 | loss: 0.02003  |  [ 280( 304),   81(  99),  107(  98),   33(   0)]     lr: 0.005\n",
      " 5-1000 | loss: 0.01932  |  [ 436( 392),  213( 264),  209( 207),  143( 138)]     lr: 0.005\n",
      " 5-1500 | loss: 0.01564  |  [ 558( 506),  319( 348),  293( 240),  331( 407)]     lr: 0.005\n",
      " 5-2000 | loss: 0.01320  |  [ 636( 571),  435( 460),  572( 511),  358( 459)]     lr: 0.005\n",
      " 6- 500 | loss: 0.01751  |  [ 191( 165),   98( 114),   87(  73),  125( 149)]     lr: 0.005\n",
      " 6-1000 | loss: 0.01236  |  [ 357( 336),  196( 239),  229( 193),  219( 233)]     lr: 0.005\n",
      " 6-1500 | loss: 0.01097  |  [ 500( 434),  315( 345),  408( 407),  278( 315)]     lr: 0.005\n",
      " 6-2000 | loss: 0.01003  |  [ 846( 751),  340( 379),  498( 505),  317( 366)]     lr: 0.005\n",
      " 6-2500 | loss: 0.01065  |  [ 980( 837),  385( 443),  638( 610),  498( 611)]     lr: 0.005\n",
      " 7- 500 | loss: 0.00799  |  [ 219( 199),   19(  35),  131( 152),  132( 115)]     lr: 0.005\n",
      " 7-1000 | loss: 0.00675  |  [ 340( 319),  268( 311),  185( 183),  208( 188)]     lr: 0.005\n",
      " 7-1500 | loss: 0.26092  |  [ 430( 402),  331( 416),  385( 342),  355( 341)]     lr: 0.005\n",
      " 7-2000 | loss: 2.83213  |  [ 639( 446),  340( 459),  619( 450),  403( 646)]     lr: 0.005\n",
      " 8- 500 | loss: 0.10516  |  [ 186( 169),   36(  17),  235( 231),   44(  84)]     lr: 0.005\n",
      " 8-1000 | loss: 0.07318  |  [ 362( 269),  122( 143),  426( 451),   91( 138)]     lr: 0.005\n",
      " 8-1500 | loss: 0.05832  |  [ 655( 485),  170( 224),  501( 487),  175( 305)]     lr: 0.005\n",
      " 8-2000 | loss: 0.05226  |  [ 826( 576),  276( 420),  671( 529),  228( 476)]     lr: 0.005\n",
      " 9- 500 | loss: 0.02127  |  [ 115(  66),  178( 209),  177( 159),   31(  67)]     lr: 0.005\n",
      " 9-1000 | loss: 0.01863  |  [ 236( 176),  244( 286),  355( 291),  166( 248)]     lr: 0.005\n",
      " 9-1500 | loss: 0.01595  |  [ 309( 235),  401( 488),  557( 406),  234( 372)]     lr: 0.005\n",
      " 9-2000 | loss: 0.01528  |  [ 459( 400),  531( 623),  754( 588),  257( 390)]     lr: 0.005\n",
      " 9-2500 | loss: 0.01468  |  [ 718( 636),  573( 656),  837( 663),  373( 546)]     lr: 0.005\n",
      "10- 500 | loss: 0.01564  |  [ 278( 193),   76( 130),   65(   4),   82( 174)]     lr: 0.0025\n",
      "10-1000 | loss: 0.01338  |  [ 351( 265),  236( 288),  322( 239),   92( 209)]     lr: 0.0025\n",
      "10-1500 | loss: 0.01184  |  [ 539( 476),  272( 332),  491( 373),  199( 320)]     lr: 0.0025\n",
      "10-2000 | loss: 0.01260  |  [ 658( 586),  334( 399),  684( 580),  325( 436)]     lr: 0.0025\n",
      "11- 500 | loss: 0.00744  |  [  72(  55),  207( 207),  194( 192),   28(  47)]     lr: 0.0025\n",
      "11-1000 | loss: 0.00900  |  [ 261( 233),  221( 231),  267( 274),  252( 263)]     lr: 0.0025\n",
      "11-1500 | loss: 0.00864  |  [ 482( 435),  281( 311),  346( 334),  392( 421)]     lr: 0.0025\n",
      "11-2000 | loss: 0.00703  |  [ 579( 527),  422( 484),  427( 390),  573( 600)]     lr: 0.0025\n",
      "12- 500 | loss: 0.01008  |  [ 105(  83),   35(  36),  295( 276),   66( 106)]     lr: 0.0025\n",
      "12-1000 | loss: 0.00789  |  [ 277( 245),  105(  95),  384( 361),  235( 300)]     lr: 0.0025\n",
      "12-1500 | loss: 0.00797  |  [ 372( 292),  227( 231),  461( 404),  441( 574)]     lr: 0.0025\n",
      "12-2000 | loss: 0.00745  |  [ 484( 398),  372( 385),  541( 474),  604( 744)]     lr: 0.0025\n",
      "13- 500 | loss: 0.02886  |  [ 194( 159),  124( 135),  121(  91),   62( 116)]     lr: 0.0025\n",
      "13-1000 | loss: 0.01971  |  [ 307( 247),  300( 349),  262( 223),  132( 182)]     lr: 0.0025\n",
      "13-1500 | loss: 0.01936  |  [ 415( 346),  363( 412),  409( 389),  314( 354)]     lr: 0.0025\n",
      "13-2000 | loss: 0.01650  |  [ 472( 381),  437( 509),  633( 592),  459( 519)]     lr: 0.0025\n",
      "14- 500 | loss: 0.01466  |  [ 182( 149),  127( 148),   44(  51),  148( 153)]     lr: 0.0025\n",
      "14-1000 | loss: 0.01143  |  [ 294( 242),  274( 284),  135( 153),  298( 322)]     lr: 0.0025\n",
      "14-1500 | loss: 0.01115  |  [ 470( 460),  345( 333),  182( 188),  504( 520)]     lr: 0.0025\n",
      "14-2000 | loss: 0.01091  |  [ 600( 565),  461( 451),  315( 316),  625( 669)]     lr: 0.0025\n",
      "15- 500 | loss: 0.01035  |  [  84(  68),  180( 187),  227( 246),   10(   0)]     lr: 0.0025\n",
      "15-1000 | loss: 0.01670  |  [ 242( 200),  216( 217),  294( 290),  249( 294)]     lr: 0.0025\n",
      "15-1500 | loss: 0.01421  |  [ 474( 430),  282( 299),  417( 390),  328( 382)]     lr: 0.0025\n",
      "15-2000 | loss: 0.01224  |  [ 700( 636),  315( 329),  445( 410),  541( 626)]     lr: 0.0025\n",
      "16- 500 | loss: 0.00899  |  [ 122(  95),   49(  89),  215( 228),  115(  89)]     lr: 0.0025\n",
      "16-1000 | loss: 0.01183  |  [ 200( 163),  164( 221),  455( 471),  182( 146)]     lr: 0.0025\n",
      "16-1500 | loss: 0.10090  |  [ 406( 319),  231( 364),  604( 474),  260( 344)]     lr: 0.0025\n",
      "16-2000 | loss: 0.07951  |  [ 515( 412),  251( 397),  732( 583),  503( 609)]     lr: 0.0025\n",
      "17- 500 | loss: 0.01491  |  [ 107( 107),  162( 218),  192( 167),   40(   9)]     lr: 0.0025\n",
      "17-1000 | loss: 0.01251  |  [ 219( 236),  206( 257),  461( 385),  115( 123)]     lr: 0.0025\n",
      "17-1500 | loss: 0.01273  |  [ 300( 303),  254( 308),  622( 483),  325( 407)]     lr: 0.0025\n",
      "17-2000 | loss: 0.01151  |  [ 396( 378),  307( 365),  746( 580),  552( 678)]     lr: 0.0025\n",
      "18- 500 | loss: 0.01663  |  [ 134( 134),  142( 141),  111( 119),  114( 107)]     lr: 0.00125\n",
      "18-1000 | loss: 0.01786  |  [ 257( 214),  230( 247),  214( 195),  300( 345)]     lr: 0.00125\n",
      "18-1500 | loss: 0.01604  |  [ 381( 352),  408( 413),  298( 257),  414( 479)]     lr: 0.00125\n",
      "18-2000 | loss: 0.01447  |  [ 454( 426),  440( 438),  524( 497),  583( 640)]     lr: 0.00125\n",
      "19- 500 | loss: 0.01029  |  [ 198( 202),   76(  58),   75(  81),  152( 160)]     lr: 0.00125\n",
      "19-1000 | loss: 0.01137  |  [ 356( 330),  121( 105),  272( 272),  252( 294)]     lr: 0.00125\n",
      "19-1500 | loss: 0.01060  |  [ 448( 397),  311( 326),  381( 357),  361( 421)]     lr: 0.00125\n",
      "19-2000 | loss: 0.00971  |  [ 588( 544),  462( 475),  519( 492),  432( 490)]     lr: 0.00125\n",
      "20- 500 | loss: 0.00452  |  [ 320( 327),  101(  84),    4(   3),   76(  87)]     lr: 0.00125\n",
      "20-1000 | loss: 0.00619  |  [ 419( 421),  143( 127),  102(  66),  337( 387)]     lr: 0.00125\n",
      "20-1500 | loss: 0.00619  |  [ 506( 501),  189( 185),  251( 219),  555( 596)]     lr: 0.00125\n",
      "20-2000 | loss: 0.00621  |  [ 653( 607),  295( 325),  362( 346),  691( 723)]     lr: 0.00125\n",
      "21- 500 | loss: 0.00828  |  [ 129( 105),   43(  37),  199( 222),  130( 137)]     lr: 0.00125\n",
      "21-1000 | loss: 0.00780  |  [ 284( 242),  147( 150),  374( 382),  196( 227)]     lr: 0.00125\n",
      "21-1500 | loss: 0.00727  |  [ 414( 372),  294( 294),  472( 455),  321( 380)]     lr: 0.00125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-2000 | loss: 0.00752  |  [ 473( 430),  403( 438),  582( 544),  543( 589)]     lr: 0.00125\n",
      "22- 500 | loss: 0.00723  |  [  45(  26),  181( 191),   52(  40),  223( 244)]     lr: 0.00125\n",
      "22-1000 | loss: 0.01199  |  [ 224( 194),  279( 289),  175( 157),  323( 361)]     lr: 0.00125\n",
      "22-1500 | loss: 0.01189  |  [ 444( 372),  380( 423),  236( 202),  441( 504)]     lr: 0.00125\n",
      "22-2000 | loss: 0.01153  |  [ 620( 548),  525( 571),  409( 378),  447( 504)]     lr: 0.00125\n",
      "23- 500 | loss: 0.01338  |  [ 143( 136),   68(  85),  214( 189),   76(  91)]     lr: 0.00125\n",
      "23-1000 | loss: 0.01126  |  [ 260( 234),  205( 219),  254( 193),  282( 355)]     lr: 0.00125\n",
      "23-1500 | loss: 0.00927  |  [ 405( 370),  363( 400),  391( 325),  342( 406)]     lr: 0.00125\n",
      "23-2000 | loss: 0.00998  |  [ 548( 499),  432( 486),  524( 459),  497( 557)]     lr: 0.00125\n",
      "24- 500 | loss: 0.00711  |  [ 198( 180),    5(  13),   53(  28),  245( 280)]     lr: 0.00125\n",
      "24-1000 | loss: 0.00762  |  [ 324( 285),  113( 142),  151( 117),  413( 457)]     lr: 0.00125\n",
      "24-1500 | loss: 0.00704  |  [ 468( 417),  249( 270),  328( 305),  456( 509)]     lr: 0.00125\n",
      "24-2000 | loss: 0.00702  |  [ 625( 556),  400( 406),  492( 505),  484( 534)]     lr: 0.00125\n",
      "25- 500 | loss: 0.01194  |  [ 159( 127),   78(  86),  167( 148),   97( 140)]     lr: 0.00125\n",
      "25-1000 | loss: 0.01151  |  [ 351( 266),  151( 211),  281( 266),  218( 258)]     lr: 0.00125\n",
      "25-1500 | loss: 0.01057  |  [ 441( 315),  219( 289),  424( 402),  417( 495)]     lr: 0.00125\n",
      "25-2000 | loss: 0.01021  |  [ 594( 455),  278( 352),  574( 555),  555( 639)]     lr: 0.00125\n",
      "26- 500 | loss: 0.00963  |  [  55(  41),    9(   0),  267( 266),  170( 194)]     lr: 0.00125\n",
      "26-1000 | loss: 0.00906  |  [ 136( 105),  186( 179),  378( 400),  301( 317)]     lr: 0.00125\n",
      "26-1500 | loss: 0.01136  |  [ 237( 212),  270( 280),  584( 588),  410( 421)]     lr: 0.00125\n",
      "26-2000 | loss: 0.00979  |  [ 430( 375),  357( 390),  708( 707),  506( 529)]     lr: 0.00125\n",
      "27- 500 | loss: 0.01059  |  [ 229( 191),   44(  72),  143( 164),   85(  74)]     lr: 0.000625\n",
      "27-1000 | loss: 0.01144  |  [ 329( 272),  214( 250),  366( 405),   92(  74)]     lr: 0.000625\n",
      "27-1500 | loss: 0.01227  |  [ 524( 405),  389( 381),  492( 585),   96( 130)]     lr: 0.000625\n",
      "27-2000 | loss: 0.01115  |  [ 747( 586),  427( 440),  540( 610),  287( 365)]     lr: 0.000625\n",
      "28- 500 | loss: 0.01944  |  [ 164( 149),  190( 213),  126( 139),   21(   0)]     lr: 0.000625\n",
      "28-1000 | loss: 0.01451  |  [ 319( 257),  240( 301),  229( 259),  213( 184)]     lr: 0.000625\n",
      "28-1500 | loss: 0.01476  |  [ 545( 483),  282( 352),  349( 369),  325( 297)]     lr: 0.000625\n",
      "28-2000 | loss: 0.01359  |  [ 724( 607),  402( 511),  498( 538),  377( 345)]     lr: 0.000625\n",
      "29- 500 | loss: 0.01309  |  [ 169( 170),   87( 116),   49(  53),  196( 162)]     lr: 0.000625\n",
      "29-1000 | loss: 0.01376  |  [ 260( 238),  228( 263),  201( 242),  312( 258)]     lr: 0.000625\n",
      "29-1500 | loss: 0.01414  |  [ 476( 465),  276( 300),  266( 317),  483( 419)]     lr: 0.000625\n",
      "29-2000 | loss: 0.01429  |  [ 674( 606),  294( 355),  363( 411),  670( 629)]     lr: 0.000625\n",
      "30- 500 | loss: 0.01825  |  [ 204( 201),   62(  77),  170( 196),   65(  27)]     lr: 0.000625\n",
      "30-1000 | loss: 0.02080  |  [ 423( 349),   74( 108),  317( 345),  187( 199)]     lr: 0.000625\n",
      "30-1500 | loss: 0.01639  |  [ 487( 367),  307( 368),  493( 521),  214( 245)]     lr: 0.000625\n",
      "31- 500 | loss: 0.01575  |  [  90(  85),  198( 187),  177( 194),   36(  35)]     lr: 0.000625\n",
      "31-1000 | loss: 0.01100  |  [ 193( 256),  247( 234),  234( 224),  327( 287)]     lr: 0.000625\n",
      "31-1500 | loss: 0.01224  |  [ 529( 574),  278( 264),  348( 350),  346( 313)]     lr: 0.000625\n",
      "31-2000 | loss: 0.01107  |  [ 652( 673),  477( 485),  375( 371),  497( 472)]     lr: 0.000625\n",
      "32- 500 | loss: 0.01408  |  [ 229( 181),   71(  97),  109(  75),   92( 148)]     lr: 0.000625\n",
      "32-1000 | loss: 0.01172  |  [ 281( 199),  249( 262),  321( 307),  150( 233)]     lr: 0.000625\n",
      "32-1500 | loss: 0.01126  |  [ 509( 394),  310( 319),  428( 467),  254( 321)]     lr: 0.000625\n",
      "32-2000 | loss: 0.01164  |  [ 627( 491),  389( 404),  519( 556),  466( 550)]     lr: 0.000625\n",
      "\n",
      "Duration: 853 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "EPOCS = 50\n",
    "PRINT_MARK = 500\n",
    "BATCH_SIZE = 50\n",
    "STOP_LOSS = 0.0025\n",
    "MIN_LEARNING_RATE = 0.0005\n",
    "\n",
    "\n",
    "for epoc in range(EPOCS):\n",
    "    losses = list()\n",
    "    quadrants = list()\n",
    "    real_quadrants = list()\n",
    "    # model_c.hidden = (model_c.hidden[0].cuda(), model_c.hidden[1].cuda())\n",
    "    train_key_sample = [key for keys in [random.sample(trainset_quadrant_to_keys[i+1], BATCH_SIZE//4) for i in range(4)] for key in keys]\n",
    "    random.shuffle(train_key_sample)\n",
    "    train_sample = [datum for sample_key in train_key_sample for datum in trainset[sample_key]]\n",
    "    \n",
    "    for batch_i, (X_train, (valence, arousal)) in enumerate(train_sample):\n",
    "        optimizer.zero_grad()\n",
    "        model_c.hidden = (torch.zeros(model_c.hidden[0].shape).cuda(),\n",
    "                          torch.zeros(model_c.hidden[0].shape).cuda())\n",
    "        \n",
    "        y_train = torch.Tensor((valence, arousal)).cuda()\n",
    "        # Apply the model\n",
    "        y_pred = model_c(X_train.cuda())  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    "\n",
    "        # Update parameters\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.cpu().item())\n",
    "        real_quadrants.append(get_quadrant(y_train[0].item(), y_train[1].item()))\n",
    "        quadrants.append(get_quadrant(y_pred[0].item(), y_pred[1].item()))\n",
    "        \n",
    "        # Print interim results\n",
    "        if (batch_i > 0 or epoc == 0) and batch_i%PRINT_MARK == 0:\n",
    "            print(f'{epoc:2}-{batch_i:4} | loss: {np.mean(losses):.5f}  |  [{quadrants.count(1):4}({real_quadrants.count(1):4}), {quadrants.count(2):4}({real_quadrants.count(2):4}), {quadrants.count(3):4}({real_quadrants.count(3):4}), {quadrants.count(4):4}({real_quadrants.count(4):4})]     lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "    \n",
    "    scheduler.step(np.mean(losses))\n",
    "\n",
    "    if np.mean(losses) < STOP_LOSS or optimizer.param_groups[0][\"lr\"] < MIN_LEARNING_RATE:\n",
    "        break\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model saved_models/AudioLSTMCNN_1675247749_011615362090984925.pt\n"
     ]
    }
   ],
   "source": [
    "latest_model_name = f'saved_models/AudioLSTMCNN_{int(time.time())}_{str(np.mean(losses))[2:]}.pt'\n",
    "torch.save(model_c.state_dict(), latest_model_name)\n",
    "print(f\"Saved model {latest_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 7430/7430 [00:24<00:00, 303.05it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "quadrants = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_c.hidden = (model_c.hidden[0].cuda(), model_c.hidden[1].cuda())\n",
    "    test_sample = [datum for key, value in testset.items() for datum in value]\n",
    "    for batch_i, (X_test, (valence, arousal)) in tqdm(enumerate(test_sample), total=len(test_sample)):\n",
    "        y_test = torch.Tensor((valence, arousal)).cuda()\n",
    "        # Apply the model\n",
    "#         model_c.hidden = (torch.zeros(model_c.hidden[0].shape).cuda(),\n",
    "#                           torch.zeros(model_c.hidden[0].shape).cuda())\n",
    "        \n",
    "        y_val = model_c(X_test.cuda())\n",
    "        loss = criterion(y_val, y_test)\n",
    "        losses.append(loss.cpu())\n",
    "        quadrants.append((get_quadrant(y_val[0].item(), y_val[1].item()), get_quadrant(y_test[0].item(), y_test[1].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.03153, median: 0.01776\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean(losses):.5f}, median: {np.median(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5045  544 1248  593]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]\n",
      " [   0    0    0    0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.68      0.81      7430\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68      7430\n",
      "   macro avg       0.25      0.17      0.20      7430\n",
      "weighted avg       1.00      0.68      0.81      7430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amity\\Anaconda3\\envs\\aimpathy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\amity\\Anaconda3\\envs\\aimpathy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\amity\\Anaconda3\\envs\\aimpathy\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix([a[0] for a in quadrants], [a[1] for a in quadrants]))\n",
    "print(\"\\n\")\n",
    "print(classification_report([a[0] for a in quadrants], [a[1] for a in quadrants]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 519\n",
    "test_location = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model_c(testset[test_index][test_location][0].cuda()).cpu()\n",
    "print(pred)\n",
    "print([denormalize(a.item()) for a in pred])\n",
    "print(testset[test_index][test_location][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, value[0][1]) for key, value in testset.items() if value and value[0][1] < (0.5, 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random results classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 7430/7430 [00:01<00:00, 4184.48it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "\n",
    "test_sample = [datum for key, value in testset.items() for datum in value]\n",
    "for batch_i, (X_test, (valence, arousal)) in tqdm(enumerate(test_sample), total=len(test_sample)):\n",
    "    y_test = torch.Tensor((valence, arousal)).cuda()\n",
    "    y_val = torch.Tensor((random.random(), random.random())).cuda()\n",
    "    loss = criterion(y_val, y_test)\n",
    "    losses.append(loss.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.12803, median: 0.10121\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean(losses):.5f}, median: {np.median(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 7430/7430 [00:01<00:00, 3933.40it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = list()\n",
    "\n",
    "test_sample = [datum for key, value in testset.items() for datum in value]\n",
    "for batch_i, (X_test, (valence, arousal)) in tqdm(enumerate(test_sample), total=len(test_sample)):\n",
    "    y_test = torch.Tensor((random.random(), random.random())).cuda()\n",
    "    y_val = torch.Tensor((random.random(), random.random())).cuda()\n",
    "    loss = criterion(y_val, y_test)\n",
    "    losses.append(loss.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.16660, median: 0.12987\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean(losses):.5f}, median: {np.median(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research machine factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimpathy",
   "language": "python",
   "name": "aimpathy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
